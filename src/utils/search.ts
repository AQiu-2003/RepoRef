import fs from "fs-extra";
import path from "path";
import { getRepoDir } from "./config.js";
import { switchBranch } from "./git.js";

// æ–‡ä»¶è·¯å¾„ç¼“å­˜ï¼Œæ ¼å¼ï¼š{ repoName_branch: string[] }
const filePathCache: Record<string, string[]> = {};

/**
 * æ‰«æä»“åº“æ–‡ä»¶å¹¶æ„å»ºç¼“å­˜
 * @param repoName ä»“åº“åç§°
 * @param branch åˆ†æ”¯åç§°
 * @returns æ‰€æœ‰æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„åˆ—è¡¨
 */
export async function buildRepoCache(
  repoName: string,
  branch: string
): Promise<string[]> {
  const cacheKey = `${repoName}_${branch}`;

  // åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯
  await switchBranch(repoName, branch);

  const repoDir = getRepoDir(repoName);

  if (!(await fs.pathExists(repoDir))) {
    throw new Error(`ğŸ“¦ Repository ${repoName} does not exist`);
  }

  try {
    console.log(
      `ğŸ“¦ Start scanning the files of branch ${branch} of repository ${repoName}...`
    );

    // é€’å½’å‡½æ•°ï¼Œç”¨äºæ‰«æç›®å½•
    const scanDir = async (
      dirPath: string,
      relativePath: string = ""
    ): Promise<string[]> => {
      const results: string[] = [];
      const items = await fs.readdir(dirPath, { withFileTypes: true });

      for (const item of items) {
        const itemRelativePath = path.join(relativePath, item.name);
        const fullPath = path.join(dirPath, item.name);

        if (item.isDirectory()) {
          // å¿½ç•¥ .git ç­‰å¸¸è§éœ€è¦æ’é™¤çš„ç›®å½•
          if (item.name === ".git" || item.name === "node_modules") {
            continue;
          }

          // é€’å½’æ‰«æå­ç›®å½•
          const subResults = await scanDir(fullPath, itemRelativePath);
          results.push(...subResults);
        } else {
          // æ·»åŠ æ–‡ä»¶è·¯å¾„
          results.push(itemRelativePath);
        }
      }

      return results;
    };

    // ä»ä»“åº“æ ¹ç›®å½•å¼€å§‹æ‰«æ
    const filePaths = await scanDir(repoDir);

    // ç¼“å­˜ç»“æœ
    filePathCache[cacheKey] = filePaths;

    console.log(
      `ğŸ“¦ Repository ${repoName} on branch ${branch} file scanning completed, ${filePaths.length} files found`
    );

    return filePaths;
  } catch (error) {
    console.error(
      `ğŸ“¦ Failed to scan the files of repository ${repoName}:`,
      error
    );
    throw error;
  }
}

/**
 * æœç´¢ä»“åº“ä¸­çš„æ–‡ä»¶
 * @param repoName ä»“åº“åç§°
 * @param searchPattern æœç´¢æ¨¡å¼ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼Œå¤§å°å†™ä¸æ•æ„Ÿ
 * @param branch åˆ†æ”¯åç§°
 * @returns åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
 */
export async function searchFiles(
  repoName: string,
  searchPattern: string,
  branch: string
): Promise<string[]> {
  const cacheKey = `${repoName}_${branch}`;

  // æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™æ„å»º
  if (!filePathCache[cacheKey]) {
    await buildRepoCache(repoName, branch);
  }

  // åˆ›å»ºä¸åŒºåˆ†å¤§å°å†™çš„æ­£åˆ™è¡¨è¾¾å¼
  const pattern = new RegExp(searchPattern, "i");

  // ä»ç¼“å­˜ä¸­è¿‡æ»¤åŒ¹é…çš„æ–‡ä»¶
  const matchedFiles = filePathCache[cacheKey].filter((filePath) =>
    pattern.test(filePath)
  );

  return matchedFiles;
}

/**
 * æ¸…é™¤ç‰¹å®šä»“åº“å’Œåˆ†æ”¯çš„ç¼“å­˜
 * @param repoName ä»“åº“åç§°
 * @param branch åˆ†æ”¯åç§°
 */
export function clearRepoCache(repoName: string, branch: string): void {
  const cacheKey = `${repoName}_${branch}`;
  if (filePathCache[cacheKey]) {
    delete filePathCache[cacheKey];
    console.log(`ğŸ“¦ å·²æ¸…é™¤ä»“åº“ ${repoName} çš„ ${branch} åˆ†æ”¯ç¼“å­˜`);
  }
}

/**
 * è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯
 */
export function getCacheStatus(): Record<string, number> {
  const status: Record<string, number> = {};

  for (const [key, files] of Object.entries(filePathCache)) {
    status[key] = files.length;
  }

  return status;
}
